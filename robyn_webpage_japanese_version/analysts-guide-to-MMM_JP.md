本資料はRobyn公式ページの[アナリスト向けMMMガイド](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM/)の日本語版です。
---
## 背景
---

### MMMとは何か？
マーケティング・ミックス・モデリング（MMM）は、プライバシーに配慮し、シグナルロスに強く、データドリブンな統計分析です。MMMはマーケティングおよび非マーケティング活動のインクリメンタルな売上影響とROIを定量化します。

MMMは、販売やウェブサイト訪問など事前に定義されたKPIに対するマーケティングおよび非マーケティング活動のインクリメンタルな影響を定量化することを目的とした計量経済モデルです。これは、マーケティング予算をマーケティングチャネル、製品、地域など間でどのように配分するかを理解するために使用される包括的なモデルであり、将来のイベントやキャンペーンの影響を予測するのに役立ちます：

![how MMM is built](https://facebookexperimental.github.io/Robyn/img/howMMMisBuilt.png)

MMMをケーキ調理の逆工程で考えてみましょう。レストランでケーキを注文し美味しいと感じたとします。そのケーキにどんな材料が使われているのか知りくなります。レシピを調べたら準備OKです！これでいつでもこのケーキを再現できます。また、レシピを基に実験を行い、他の材料でも成功するかや、どの材料の比率がより美味しい結果をもたらすかを試すことができます。

MMMもこれと同じです。時間をかけてビジネスKPI（ケーキ）に影響を与える要因（材料）をよりよく理解することができ、柔軟な対応が可能になります。

MMMは昔から存在しておりますが、再び注目を集めています。これには以下のような主な理由があります：
- **プライバシーを尊重し、シグナルロスに強い** - MMMの主な強みの一つは、シグナルロスに強いことです。マルチタッチアトリビューションなどの効果測定モデルはオンラインシグナルに大きく依存しています。しかしMMMはユーザーレベルのデータを必要とせず、代わりにキャンペーンレベルのデータなど集計データを使用します。
- **包括的** - MMMは、包括的な計測手法であり、クロスチャネルの測定が可能なソリューションです。一つの分析で全てのマーケティングチャネルのコンバージョンへの影響を測定します。MMMは、マーケティング活動（オンラインおよびオフライン）と非マーケティング活動（価格、プロモーション、季節性、流通など）の双方の影響を考慮に入れることも可能です。
- **柔軟性** - MMMは柔軟なモデル作成が可能であり、ビジネスタイプ（例：ゲーム、Eコマースなど）やビジネスKPI（例：収益、販売個数、ウェブサイト訪問など）に基づいて調整が可能です。

### MMMは実際にどのように機能するのか？
MMMにはいくつかのステップがあります。ハイレベルなステップは次のようになります。：

| インプット（外部要因とマーケティング活動） → | インプレッションおよびビジネス指標 → | MMMによる統計回帰分析 → | データのアウトプット |
| --------- | ----------- | -----------------   | -----------------   |

正確にMMMを実施する方法は地域、業界、会社によって異なります。MMMは回帰モデルによって、KPIを説明する方程式を導き出します。この方程式は、各変数の変化がKPIにどのような意味を持つかを表します。売上に影響を与えると予想される一連の説明変数を使用して、目的変数変数（時間経過に伴う販売量）を予測します。

MMMを実施する際には、複数のステップがあります。以下に各ステップとおおよそのタイミングを示します - これらは最初のモデリングを実施する際の一般的なものあり、モデルをリフレッシュする場合や実装方法（例：パートナーソリューションの活用）によって短縮可能です：

| ステップ | 説明 | タイミング |
| --------- | ----------- | -----------------   |
| ビジネス上の質問とスコープを定義する | 一般的な研究や分析と同様に、調査によって明らかにしたい主要なビジネス上の質問と目的を定義することが重要です。これにより、MMMの設計と実行方法が形作られ、MMMから最大の価値を得るのに役立ちます。この詳細は、[Collecting Measurement Business Questions section](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM/#collecting-your-measurement-business-questions) セクションにあります。 | 1-2週間 |
| データ収集 | データ収集はMMMプロジェクトの中でも最も重要で時間がかかるステップの一つです。販売（または別のKPI）、メディア、非メディアマーケティング活動（例：プロモーション）、マクロ経済要因の時系列データを収集し、MMMで利用できる形にクリーニングおよび加工を行う必要があります。正確で品質の高いデータの収集が重要です - 不正確または品質の低いデータをMMMにインプットすると、不正確で品質の低いアウトプットにつながります。このステップの詳細は、[Data Collection](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM/#data-collection) セクションにあります。 | 4-6週間 |
| データレビュー | データ収集に加えて、データレビューはMMMプロジェクトの中で最も重要なステップの一つです。これには、モデリングが始まる直前にすべての処理されたデータが正確であるかを徹底的に確認する作業が含まれます。データレビューではデータのギャップやエラーが明らかになることがあり、それによりさらなるデータ収集が必要になる場合があります。上述したように、不正確または品質の低いデータをインプットした結果として不正確または品質の低いアウトプットにつながります。このステップの詳細は、[Data Review](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM#data-review) セクションにあります。 | 1-2週間 |
| モデリング | すべてのインプットデータが正確であることが確認できたら、次のステップはモデル構築です。モデリングは反復プロセスになります - 一貫してモデルの再実行および微調整が行われます。このステップの時間と労力は、スコープと複雑さに基づいて大幅に変わる可能性があります。このステップの詳細は、[Modeling Phase](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM/#modeling-phase) セクションにあります。 | 4-8週間（MMMの範囲に依存） |
| 分析とレコメンデーション | モデリングに満足したら、次のステップはアウトプットのデータと結果を分析し、元々のビジネス上の質問に基づいて実用的なレコメンデーションを行います。MMMからはさまざまな出力とメトリクスをアウトプットとして得られますが、このステップの詳細は、[Applications of the Model](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM#applications-of-the-model-) セクションにあります。 | 2-4週間 |

### MMMのオプションについて（例：DIY、SaaS、3P）
MMMがあなたのビジネスに適していることがわかった場合、おめでとうございます！

MMM実装方法は、一般的に3つです。Metaでは手段に関係なくすべての広告主をサポートしています。3つの方法はそれぞれコストとリソースのトレードオフのレベルが異なります：

![MMM trade-offs](https://facebookexperimental.github.io/Robyn/img/mmm-tradeoffs.png)

1. <u>サードパーティのMMMベンダーと協力する</u>:
   MMMを専門とするサードパーティベンダーは通常、問題設定、データ収集、モデリング、結果のレポーティング/レコメンデーションなど、全体をカバーします。ほとんどのベンダーはシミュレーション/最適化および予測機能を備えたMMMを実行するためのソフトウェアを提供しています。

   - 長所: エンドツーエンドのサービスを提供し、他のオプションと比較して最も必要とする時間と労力が少ない（ベンダーによっては、）MMMの結果をベンチマークと比較できる場合があります。
   - 短所: ベンダーはコストを請求し、他のオプションと比較して通常最も高価なオプションです。

   **<em>Metaはどのように支援できるか？</em>**

   Metaには、Meta MMM Preferred Partner Programの一部である推奨サードパーティMMMパートナーがいます。これらのパートナーは、マーケティングサイエンスMMMパートナーシップチームによって検証された方法論に基づくMMMを保有しています。[Measurement Partner website](https://www.facebook.com/business/m/measurement/partners)でバッジ付きパートナーの完全なリストを見ることができます。

2. <u>SaaSプラットフォームまたは半自動MMMツールを使用する</u>:
   新しいテクノロジーにより、特別な統計知識を必要とせずに、ポイントアンドクリックでMMMを構築できます。MMM SaaSソリューションは、自動化されたモデリング手法を提供し、定期的に実行でき、通常は最適化およびシミュレーション機能を含んでいます。

   - 長所: MMMやデータ分析の専門知識を持たない人に適しており、サードパーティのMMMベンダーよりも安価です。
   - 短所: MMMベンダーと協力する場合よりもコンサルティングサービスは少ないです。

   **<em>Metaはどのように支援できるか？</em>**

   サードパーティの専門MMMベンダーと同様に、私たちはMMM SaaSソリューションを提供する推奨パートナーも持っています。完全なパートナーリストは、[Measurement Partner website](https://www.facebook.com/business/m/measurement/partners)で見ることができます。

3. <u>社内でMMMソリューションを構築する</u>:
   すべての作業を社内で実行および管理したい企業には、MMMソリューションをインハウスで構築するオプションがあります。

   - 長所: 人件費と時間を除いて、MMMを実行するための継続的なコストはありません。
   - 短所: 社内のデータ分析/データサイエンスのリソースが必要であり、すべてのオプションの中で最も内部的な時間とリソースへの投資が必要です。

   **<em>Metaはどのように支援できるか？</em>**

   Metaマーケティングサイエンスチームは、自社開発ユーザーが使用できるオープンソースのRコードであるProject Robynを構築しました。このコードは、詳細なドキュメントとステップバイステップのガイドとともにGitHubおよびこのウェブサイトで利用可能です。

### 効果測定に関わるビジネス上の質問を収集する

MMMの旅を始めるとき、効果測定を通じて答えたいすべてのビジネス質問を収集することが重要です。MMMはすべての質問に対する最適な解決策ではないかもしれません。実際、インクリメンタリティ測定（例：コンバージョンやブランドリフト）、アトリビューション、または他の何かがより適切な解決策になる場合があります。質問をまとめた後、適切な効果測定ソリューションを各質問にマッピングしましょう。

MMMで適する般的なビジネス上の質問は以下のとおりです：
1. 各メディアチャンネルはオンラインおよびオフラインでどれくらいの売上を生み出したか？
2. 各マーケティングチャンネルのROIは何か？
3. KPIを最大化するために、どのようにチャネルごとに予算を割り当てるべきか？
4. 次のマーケティング投資はどのチャネルに行うべきか？
5. 各主要マーケティングチャネルに適した投資水準はどれくらいか？
6. マーケティングプランにXの変更を加えた場合、売上にどのような影響があるか？
7. マーケティング予算をX％削減する必要がある場合、どこから資金を削減すべきか？
8. Metaなどのチャンネルのパフォーマンスは、運用方法（例：キャンペーン目的、フリークエンシー、クリエイティブの質、ターゲティング戦略）によってどのように変化するのか？
9. 価格を上げるべきか？ また、どれくらい上げるべきか？
10. 競合他社の広告が自社ブランドのパフォーマンスにどのような影響を与えるか？
11. 販売促進活動がどれだけの増収をもたらすか？

これらの質問や仮説に最適な回答できる手法がMMMである場合、質問に応じて入力変数とモデル構造を決定します。たとえば、広告主が上記の質問3に答えたい場合、キャンペーン目的レベルやクリエイティブレベルで細かい粒度のデータを収集し、モデルの入力として使用する必要があります（後で詳細について説明します）。このステップはMMMから最大の価値を得るために非常に重要な前処理ステップです。

## プリモデリングフェーズ
---
### データ収集

ビジネス質問をすべて収集し、MMMで答えを得たい質問を理解したら、データ収集を開始しましょう。データ収集はMMMプロジェクトの中で最も重要で時間がかかるステップの一つです。正確で品質の高いデータを収集することが重要です。不正確または品質の低いデータをインプットとして使用すると、不正確で品質の低いアウトプットにつながります。複数の異なるソースから同じ形式でデータを収集するのは困難であり、最も時間がかかるステップになる可能性があります。データ収集には少なくとも4週間を割り当ててください。

データ収集に関して考慮すべき複数の要因があります。

1. <u>実績データと計画データ</u>:
   実際に発生したイベントのデータを優先して収集し、モデリングすることが重要です。たとえば、Facebookのメディアプランで計画したインプレッションと支出ではなく、実際に発生したインプレッションと支出の実績を収集することを目指してください。計画データは常に実際の出来事を反映しているわけではないため、計画データをモデルに含めることで不正確なデータがインプットとなり、その結果アウトプットが不正確になる可能性があります。ただし、実績データが利用可能かどうかはマーケティング活動のトラッキング方法に依存します。実績データが利用できない場合は計画データの使用を検討しても良いでしょう。例えば、OOH広告（屋外広告など）はインプレッションをトラッキングすることが難しいため、計画されたリーチまたは支出を使用を検討しましょう。

2. <u>目的変数と説明変数</u>:
   収集するデータセットについては、目的変数と説明変数を区別する必要があります。
   - <em>目的変数</em>: MMMがモデリング対象とする主要なKPI/指標です。目的変数として一般的に使用されるデータは売上ですが、業界に応じて異なるデータを使用することができます。（例：通信の場合はアカウント登録数、銀行の場合は住宅ローン申請数など）

     - 目的変数として使用するデータを選択するときは、ビジネスにとって最も重要なKPI/指標は何かを考えてください。

   - <em>説明変数</em>: MMMにおいて目的変数に影響を与えると考えられる変数または要素です。説明変数として一般的に使用されるデータには、メディア、非メディアマーケティング（例：プロモーション、割引）、季節性（例：天候、祝日）、マクロ経済要因（例：経済成長）が含まれます。

     - 説明変数として使用するデータを選択するときは、目的変数に影響を与える要素は何かを考えてください。時系列データとして利用可能かどうかによりますが、理想的には目的変数に影響を与えるすべての要素を説明変数に含めることが望ましいです。

3. <u>どの指標を収集するべきか？</u>:
   前述の通り、目的変数として収集する指標は、ビジネスにおいて最も重要なKPIに依存します。売上金額や売上個数が一般的に使用されますが、これは業界によって異なる場合があります。

   説明変数は、マーケティング活動のタイプによって異なります：
   - メディア活動：メディア活動の結果として収集されるデータは、理想的にはメディアに接触した「ヒトの目」の数を反映すべきです（例：インプレッション、GRP）。支出も収集する必要がありますが、これは投資対効果（ROI）を計算するために必要になります。モデルへの直接入力としては、消費者がメディア活動をどのように消費したかの指標である露出指標を使用するのが最善です。たとえば、テレビに1ドルを費やした場合とFacebookに1ドルを費やした場合では、リーチが異なる可能性があります。
     - デジタルアクティビティの場合、一般的に使用される指標はインプレッションです。クリックは、ビュースルーコンバージョンを考慮に入れないため避けるべきです。広告を見てクリックせずにコンバージョンするユーザーがいる可能性があります。
     - テレビやラジオの場合、一般的に使用される指標はグロスレーティングポイント（GRP）またはターゲットオーディエンスレーティングポイント（TARP）です。
     - 新聞や雑誌などの印刷物の場合、一般的に使用される指標は読者数です。
     - 上記を参考に、他のチャネルに対しても「ヒトの目」またはインプレッションを反映したデータを収集することを目指してください。

   <em>ペイド vs オーガニック？</em>

   かつてはよりアクションに繋げやすい結果を得るために、ペイドメディアのデータのみを収集しモデル化するのがベストプラクティスでした。（オーガニックアクティビティをコントロールすことは困難なため）
   しかし、オーガニックコンテンツ（例えばFacebook上のブランドコンテンツ）などで消費者と関わりを持つ選択肢が増えれば、それらをモデルに含めることが有効な場合があります。Robynはオーガニックアクティビティのモデリングを可能にします。
   方法の詳細は[こちら](https://facebookexperimental.github.io/Robyn/docs/features#organic-variables)です。

- 非メディアマーケティング活動（例：プロモーション、割引）：一般的に、時系列の価格データまたはプロモーション実施有無を示すダミー変数などが使用されます。個別のプロモーション内容（例：1個購入で1個無料 vs 購入でプレゼント）を個別に測定する必要がある場合、各プロモーションごとに別のダミー変数を作成してください。
- 季節性と祝日：季節性や祝日など、目的変数に大きな影響を与える外部要因は、説明変数としてモデルに含める必要があります。季節性と祝日をモデルに組み込むために2つのオプションがあります：
  - Robynは、時系列データ予測用のMetaオープンソースの[Prophet](https://facebook.github.io/eatures#meta-prophet)を組み込んでおり、目的変数データをトレンド、季節性、祝日に分解します。Prophetは季節性と祝日の影響を自動で計算するため、非専門家にとって良いオプションになるでしょう。Prophetの詳細は、[Feature Engineering](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM#feature-engineering)セクションで説明しています。
  - あるいは、外部データを用いて季節性や祝日に関するデータを収集することもで可能です。これは季節性がビジネスにどのような影響を与えるかによります（例えば、変動があるビジネスなど）：
    - 季節（例：夏 vs 冬）を通して、例えば気温が一般的に使用さます。また、重要な期間や特定のイベント（例：クリスマス、売上に影響する政策変更）については、ダミー変数を使用するのが一般的です。上記と同様に、特定イベントを個別に測定する必要がある場合、必ず個別のダミー変数を作成してください。
- マクロ経済要因：これらの要因がビジネスにどのように影響するかに依存しますが、一般的に使用される指標とデータセットには、GDP成長率、失業率、インフレ率などが含まれます。

4. <u>どの程度の期間のデータを収集するべきか？</u>:
   頑健な結果を得るためには、MMMには最低2年間分の週次レベルの実績データが必要です。月次データしか利用できない場合は、モデルのデータポイント数を増やすために2年以上（例：4-5年間）を収集することを強くお勧めします。理想的には、より多くのデータがあればあるほど良いです。これにより、モデルはビジネス成果に対する季節性の影響をより頑健に捉えることができます。

5. <u>どれくらい詳細なデータを収集するべきか？</u>:
   より詳細なデータを収集し、より細かい粒度でモデリングすることには大きな利点があります。MMMベンダーのEkimetricsのホワイトペーパーによると、Metaをより細かい粒度でモデル化することで、75％のケースでMMMが改善されました。

   より細かい粒度でデータを収集およびモデリングする利点には以下のものがあります：
   - より正確なモデル：Ekimetricsのホワイトペーパーによると、Metaをより細かい粒度でモデル化すると、MMMのモデル適合指標が改善されました。より細かい粒度のデータを用いることで、モデルはインプットとして利用した各戦術の効果と目的変数への影響をより正確に把握できます。
     - 例えば、ブランド施策と獲得施策を別々の要素に分けてモデル化することで、モデルは両方の影響をより正確に計算できます。パフォーマンス活動が売上により大きな影響を与えると予想されます。一方で、すべてを一緒にモデル化すると、モデルはおそらくブランド施策と獲得施策の両方の平均的な影響を計算するため、精度が低下すると考えられます。
   - よりアクションに繋げやすい結果：細かい粒度のデータでモデリングすることで、よりアクションに繋げやすい結果が得られます。
     - 例えば、すべてのデジタル活動をまとめて「デジタル全体」としてモデル化すると、全体的なレベルで結果が出されます。各デジタルプラットフォームは大きく異なる運用を行なっている可能性があるため、全体的な結果では次に何をすべきかを理解するのが難しくなります。代わりに、Metaを他のデジタルプラットフォームから切り離してモデル化すると、よりアクションに繋げやすい洞察が得られます。

   しかし、常に詳細なデータを収集して、細かい粒度でのモデリングが可能なわけではありません：
   - データの利用可能性：詳細なデータは常に利用可能なわけではなく、データソースに依存します。ほとんどのメディアチャネル、特にデジタルの場合、詳細なデータが利用可能ですが、これらのチャネルがどのように追跡されているかを確認する必要があります。
     - 詳細なMetaデータは、MetaのMMMデータUIを通じてアクセスできます。詳細は後ほど説明します。メディアデータ以外は、データの収集方法と収集者に依存します。
     - 内部で収集されるデータ（例：プロモーションデータ）の場合、通常ある程度細かい粒度で利用可能ですが、これはデータセットによって異なります。
     - 外部データソースから収集されるデータ（例：マクロ経済データ、天候）の場合、通常詳細なデータを用意する柔軟性は低いです。
   - データのバリエーション/ボリューム：一般に、モデルがデータセットから堅牢な示唆を得るためには、2つの要因を考慮する必要があります：
     - バリエーション：回帰モデリングは目的変数と説明変数の間の相関関係に基づくため、データにはある程度のバリエーションが必要です。たとえば、売上は週ごとの変動があるが、TVCMが全期間にわたって一定である場合、モデルはテレビが売上にどのように影響を与えたかを判断するのが難しくなります。
     - ボリューム：また、モデルが堅牢な結果を計算するためには、十分なデータ件数が必要です。これを判断する一つの方法は、データ件数が少ないマーケティング活動が目的変数に十分な影響を与える可能性があるかどうかを自問することです。たとえば、ある地域で少量のサンプリング配布活動が行われた場合、これが全体的な売上に影響を与えるでしょうか？そうでない場合、モデルがサンプリング配布活動の売上に対する影響を計算することは難しいでしょう。

   データセットに十分なバリエーションとボリュームがない場合、そのデータセットをモデルから除外する方が良いかもしれません。必要以上に多くの変数を含めると、モデルのオーバースペックにつながり（[Feature Engineering](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM#feature-engineering)セクションの**モデル設計**を参照）、ノイズが増え、モデルが正確に影響を計算するのが難しくなります。ある活動が目的変数に影響を与えるという強い仮説があるが、収集されたデータが十分なバリエーションとボリュームを満たしていない場合、その活動を含めたモデルと含めないモデルをどちらも作成し、モデル適合指標で判断してその活動をモデルに含めるかどうかを判断できます（[Applications of the model](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM#applications-of-the-model-)セクションの**マーケティングミックスモデル出力の解釈**を参照）。

   データ粒度の考え方は複数あります：
   - 時間：ベストプラクティスとして、週次レベルでデータを収集することを目指してください。日次データも許容されますが、これには追加のデータ検証が必要です。その理由は、日次データにはより多くのバリエーションがあることで正確性が向上し、モデリングの柔軟性が高まる可能性もありますが、反対にモデルにより多くのノイズが発生するリスクも伴います。
   - 地域：地域レベルでデータを収集することをベストプラクティスとして目指してください。これは、地域ごとのニュアンスを考慮する必要があるためです。たとえば、米国の沿岸州では他の州と比較して異なる消費者行動があるかもしれません。地域レベルのデータが利用できない場合、国全体のデータも許容されますが、地域レベルの消費者行動やマーケティング活動を踏まえて詳細なモデルを作成するべきかを判断してください。
   - ブランド/ビジネスユニット：これは何種類のモデルを構築すべきかの判断基準になります。一般的には、ブランド/ビジネスユニットごとに分割することが多いです。たとえば、自動車メーカーの広告主はそれぞれの車種に対して別々のマーケティング活動を頻繁に行っているため、各車種ごとに別々の予測モデルを構築することが多いです。ブランド/ビジネスユニットごとのモデル分割方法方に正解はありませんが、どのように意思決定が下され、それが結果として反応するかを考慮するとと良いでしょう。たとえば、住宅ローンとクレジットカードなどの異なる金融サービス製品に対して別々のメディアプランとマーケティング予算が設定されている場合、これらは別々のモデルとして実行することは理にかなっています。
   - 説明変数の粒度：説明変数においても粒度の細かいデータを収集し、モデル化することも可能です。たとえば、歴史的にデジタルマーケティング活動は、メディア支出全体に占める割合が低いことが多かったため、一つの変数として合算した上でモデル化されていました。しかし、今日ではデジタルメディアはより細分化され、複雑化しているため、ベストプラクティスとして分割することが推奨です（下記を参照）。

![exampleROI](https://facebookexperimental.github.io/Robyn/img/exampleROI.png)

最低限、デジタルメディアはチャネル/パブリッシャーレベルで分割することが望ましいです。これは運用やパフォーマンスがメディアごとに大きく異なるためです（例：SNS vs 検索 vs ディスプレイ）。また、特定のチャネル内でさらに詳細化することがベストプラクティスですが、これはモデルからどの粒度の示唆を得る必要があるかに依存します。例えば、Facebookの静止画広告と動画広告のパフォーマンスはどう異なるでしょうか？
より粒度の細かいデータ（例：クリエイティブ単位）を収集し、最終的なモデルで使用しない場合でも、モデル結果を解釈する際に役立つ可能性があります。たとえば、モデルからFacebookのROIが$2である結果が得られた場合、それが$2である理由を説明するさらなる情報はありません。Facebookのメディアおよびクリエイティブの運用に関する追加情報が、Facebookのパフォーマンスをさらに詳細に分析するのに役立ち、運用の品質を事前に評価するためのスコアカードを構築することができます。

<u>始め方は？</u>

上記のすべての考慮事項に基づいて、MMMに含めたいさまざまな変数をマッピングすることから始めましょう。事前に変数を明確にすることで、プロジェクト管理の観点から、必要なデータを収集する責任者を明確にするのに役立ちます。

これを支援するために：
  - 目的変数の時系列推移グラフを作成してみてください。大きなピークや谷を確認し、それらのピークや谷を引き起こした特定のアクティビティやイベントが何であったかを理解しましょう。
  - データスキーマを作成することも視覚化のための簡単だが役立つ方法です。下の例を参照してください。特定の変数はビジネスや業界ごとに異なります：

![data schema](https://facebookexperimental.github.io/Robyn/img/dataSchema.png)

これが明確になれば、データ収集テンプレートを使用して関連するステークホルダーと共有することができます。

<u>Meta MMMフィード</u>：
Metaのデータ収集を支援するために、Meta公式のMMMフィードを活用できます。このフィードは、MetaにおけるMMMデータの情報源であり、最も正確で標準化されたコアメトリックを、最適なMMMワークフローのためのより深い次元と詳細度で提供します。データには詳細が含まれており、日、国、地域、配置、目的、形式、キャンペーン、広告セットごとに分割することができます。

Preferred Partner Programを通じてベンダーはすでにMeta MMMフィードへのアクセスを持っていますが、自己サービスのユーザーインターフェースがあります。社内モデリングやバッジのないサードパーティを通じてフィードにアクセスする場合は、Meta担当者に連絡してください。

<u>追加のデータ収集のヒント</u>：
これまでの経験に基づく、データ収集を容易にするためのいくつかのヒントを以下に示します：

  - メディアまたはマーケティングプランのデータを収集する：これらはインプットとして使用すべきではありませんが、情報源として非常に価値があります。プランは収集すべきデータを明確にし、収集されたデータが正確であるかを確認するのに役立ちます。
  - データサンプルから始める：全期間の完全なデータセットを収集する代わりに、サンプル（例：数ヶ月のデータ）を収集して、それが正しく望ましい形式であるかを確認します。これにより、必要以上の作業が発生する可能性がありますが、余分な注意を払うことで、後々の時間と労力を節約し、データの再取得を防ぐことができます。
  - 週の開始日を明確にする：週次モデルを実行する場合、データが開始する曜日（例：日曜日始まり vs 月曜日始まり）を事前に明確にしてください。すべての関係者で足並みをそろえれば、後々の時間と労力を大幅に削減できる可能性があります。

### データレビュー

すべてのデータを収集したら、データレビューを実施し、正確さ、メディアプランと合致しているか、期待したデータが得られているか、目的となるビジネス上の質問に答えられるかを検証します。

データ収集と並んで、データレビューはMMMにおいて最も重要なステップの一つです。収集されたデータがレビューされず、不正確なままMMMに使用された場合、データのアウトプットも不正確で信頼できないものになります。

<u>どのようにデータレビューを行うか</u>？

多くの異なる時系列データセットの正確性をレビューすることは、困難で時間のかかるプロセスです。最も細かいレベルでデータを徹底的にチェックすることが最も信頼性が高くなりますが、時間もかかります。反対に概要レベルでの確認は非常に短時間で行えますが、信頼性が高くなるとは限りません。

以下はデータレビュー用のチャートの例です（これらのチャートは現在のロビンコードには含まれていません）。
  - 以下のチャートは、収集されたデータ入力の記述統計または基本的な概要を提供します。これらのチャートは、欠損データや不完全なデータがあるかどうかを判断するのに役立ち、さらに調査が必要な特定の変数（メディアチャネルなど）を特定するのに役立ちます。


<img alt="nonmissingdata" src={https://facebookexperimental.github.io/Robyn/img/nonmissingdata.png} />

<img alt="observationsperyear" src={https://facebookexperimental.github.io/Robyn/img/observationsperyear.jpg} />

<img alt="observationsperweek" src={https://facebookexperimental.github.io/Robyn/img/observationsperweek.jpg} />

- 以下のチャートは、すべての異なる変数間の相関を分析するのに役立ちます：
    - チャート3aは、各説明変数どうしの相関を表します。これは、2つ以上の説明変数が互いに高い相関を持つときに起こる多重共線性を判断するのに役立ちます。多重共線性は、回帰モデルにとって問題となる可能性があり、特にすべての説明変数が互いに高い相関を持つ場合、モデルは異なる説明変数のそれぞれの影響を計算することが困難になります。これは、最終モデルにどの変数を含めるかを決めるのに役立ちます。


<img alt="correlationchart" src={https://facebookexperimental.github.io/Robyn/img/correlationchart.png}/>

  - あるいは、チャート3bは、目的変数との説明変数の間の相関を表します。これは、目的変数と説明変数の間に期待される関係があるかどうかを可視化するのに役立ち、特定の説明変数を含めるべきかどうかを決定するのに便利です。


<img alt="correlationwithdependent" src={https://facebookexperimental.github.io/Robyn/img/correlationwithdependent.png}/>


- 次のチャートは、収集したデータの正確さをチェックするのに役立ちます。チャート4と5を使って、メディアプランと照らし合わせたり、メディア活動に精通した別の関係者からチェックしてもらうことで、収集したデータの信頼性を確かめるのに役立ちます。
さらに、特定のビジネス上の質問に答えるためにより詳細なデータが必要となる場合、収集したデータがその質問に答えるために十分な粒度であると確認することが重要です。

<img alt="mediaspendintime" src={https://facebookexperimental.github.io/Robyn/img/mediaspendintime.png}/>

<img alt="fbtrendbyyear" src={https://facebookexperimental.github.io/Robyn/img/fbtrendbyyear.png}/>


最終的には、データレビュープロセスの最後に、収集されたすべてのデータが正確であることを確信を持った上で次のステップに進みましょう。



## モデリングフェーズ
---

ここまでのガイドにしたがって、必要なデータを正確に収集およびレビューできた方はおめでとうございます！RobynでMMMを実施する旅の約半分を完了したと考えてください。データ収集とレビューは非常に重要でありながら時間がかかるステップです。しかし、Robynを使用することでRobynのコア機能を自分で開発することなく利用できます。Robynはモデリングのためのスクリプトをエンドツーエンドで提供し、これを全体的にまたは部分的に利用してMMMプロジェクトを強化することができます。データ入力が完了しており、[必要なテンプレート](https://github.com/facebookexperimental/Robyn/blob/main/R/data/dt_simulated_weekly.RData)に従い、[ステップバイステップのデモスクリプト](https://github.com/facebookexperimental/Robyn/blob/main/demo/demo.R)に従う場合、モデリングフェーズを完了できます。

### フィーチャーエンジニアリング
フィーチャーエンジニアリングは、予測モデルが未知のデータに対するモデルの精度を改善するため、インプットデータをより形に変換するプロセスです（フィーチャーエンジニアリングの詳細は[こちら](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)）。今日のMMMはより洗練されており、異なるフィーチャーエンジニアリングのテクニックが導入されています。フィーチャーエンジニアリングはデータ収集と同じくらい重要であり、このプロセスによってモデリングにおけるインプットデータの扱い方が変わります。したがって、それぞれのテクニックの背後にある前提を理解することが非常に重要です。さもなければ、誤解を招く結果となる可能性があります。

<u>プロフェットによる季節性分解</u>:

業界によっては、目的変数（例：売上、コンバージョン）が基本的な季節性トレンドによって影響を受ける可能性があります。RobynとMMMは時系列データを使用しているため、時系列分析（[wiki](https://en.wikipedia.org/wiki/Time_series)）を使用して季節性トレンドを特定し、それを最終モデルに組み込むことができます。

[Prophet](https://facebook.github.io/prophet/)は時系列データの予測のためのMetaのオープンソースコードです。Prophetは自動的にRobynコードに組み込まれており、データをトレンド、季節性、祝日、平日の影響に分解して、モデルのあてはまりと予測能力を向上させます。従来は、季節性および祝日データは追加のダミー変数として収集およびモデル化する必要がありました。しかし、Prophetはこのプロセスを特にRobynとMMMの初心者にとってはるかに簡単にします。

Robynコードでは、Prophetを使用して時系列のベースラインを簡単に追加できます。モデリングにどのベースラインを含める必要があるかが明確でない場合は、以下の説明を参照してください：

- **トレンド**：長期的でゆっくりと変化する動き（増加または減少方向）です。マーケティングでは、トレンドは特定のカテゴリーでの一般的な市場成長や徐々に進行する経済の低下など、長期的なモメンタムを生み出す要因によって生成される場合があります。
- **季節性**：通常は年次でキャプチャされる繰り返しの挙動です。例えば、業界やカテゴリーによっては、特定のブランドが夏に冬よりも多くの売上を上げる可能性があります。
- **平日**：週内でキャプチャされる繰り返しの挙動です。これは日次データが利用可能な場合にのみ使用できます。
- **祝日/イベント**：従属変数に大きな影響を与える祝日やその他のイベントです（例：国民の祝日、大規模なセール期間など）。

![prophet_decomp](https://facebookexperimental.github.io/Robyn/img/prophet_decomp.png))

分析対象のビジネスのトレンド/季節性を示すデータがない場合、少なくともトレンドと季節性の要素についてProphetの使用を検討することをお勧めします。しかし、モデルや測定対象業界の複雑さが増すにつれて、他のデータソースを収集するなどして、時間ベースのトレンドを考慮する追加的な方法を検討する価値があるかもしれません。

**<em>より専門的なヒント：休日とイベント情報をカスタマイズする</em>**

デフォルトのProphetの「dt_holidays」ファイルから、59カ国の祝日データを使用できます。リストを確認するには、**`data("dt_prophet_holidays")`**を実行します。しかし、この情報が必ずしもビジネスカレンダーと完全に一致するとは限りません。例えば、eコマースビジネスでは、商品が祝日の前に配達される必要があるため、祝日の数日前に収益が大きく変化する場合があります。また、他のビジネスでは、国のカレンダーとは独立した独自の大規模な販売日があるかもしれません。この場合、以下を試すことができます：
- 祝日データセットをカスタマイズする：ビジネスが持続的な影響または事前の影響を持つ場合は、既存の休日データセットの情報を変更することを検討してください。さらに、（休日に限らず）イベントの任意のタイプをこのテーブルに追加することができます（例：学校の休み、ブラックフライデー、サイバーマンデーなど）。
- コンテキスト変数として追加する：Prophetの「祝日」情報を使用する場合、さまざまな休日/イベントが1つの変数として集約され、モデル化されます。特定の日またはイベントの影響を別の変数として測定する必要がある場合は、その情報を**`context_vars`**に追加することを検討してください。この場合、Prophetの祝日と追加した列の間で重複する情報を提供しないように注意してください。また、特定の異なる休日やイベントを説明するために良質なデータが収集されている場合、それを特定の説明変数としてモデル化し、Prophetでの祝日オプションをオフにすることもできます。

<u>モデル期間</u>

MMMモデルは実績データに基づいて構築されるため、実績データから特に使用するための正しい期間を選択することが重要です。長い期間と短い期間を使用することにはそれぞれ利点と欠点があります：
- 長い期間のデータを利用する利点は、完全な実績（例：4年間）を使用して、トレンド、季節性、祝日の効果をより正確に把握することができます。
- 代わりに、メディア、オーガニック、コンテキスト変数のため、特定の範囲（例：18ヶ月）を切り出してモデリングすることは、現在のビジネスおよびマーケティングシナリオをより正確に反映するためのより良い選択肢です。

Robynでは、[model window](https://facebookexperimental.github.io/Robyn/docs/features#continuous-reporting) 機能を利用してこのバランスを達成することができます。たとえば、Robynの統合データセットが208週をカバーしている場合、ユーザーは利用可能なデータのサブセット（例：100週）を「モデリング期間」として設定でき、トレンド／季節性／祝日変数は全体の208週から作成することで、時系列分解の精度が向上します。

モデル期間の決定は簡単な質問ではありません。これは各ビジネスやデータセットによって異なりますが、以下に一般的な考慮事項をいくつか示します：
- **ビジネスコンテキスト（ビジネス背景）**
  ビジネスコンテキストは常に重要であり、分析者は「モデリングにおいて最新の結果を提供しつつ、どれだけの期間があれば十分か」を自問する必要があります。マーケティング活動方針などの変更、広告プラットフォームの進化、外部マクロ要因などの要因を考慮するしてください。[データレビュー](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM#data-review) セクションで触れたように、データをチャート化することは常に役立ちます。

- **データの希薄さ（何件のデータを集められるか？）**
  データの希薄さも考慮する必要があります。モデリングウィンドウに十分なデータポイントが含まれていることを確認する必要があります。推奨されるデータポイントの比率は、1つの説明変数に対して10件のレコードです。たとえば、最近の6ヶ月のデータでモデルを実行する場合、週次データはモデルに適合させるには希薄すぎるため、このケースでは日次データが推奨されます。データセットを分割してモデリングするには十分な量でない場合、利用可能な期間全体でモデルを作成させることができます。

最終的にどのモデル期間を使用するか確信が持てない場合も心配しないでください！複数の異なる期間を試し**反復的な**プロセスの一部として実験してみてください。

<u>モデル設計</u>

モデル設計は、すべてのビジネス上の質問に答えることと、モデルの仕様を正しく設定することのバランスを取ることです。モデルのオーバースペックは、モデルに含まれる説明変数が多すぎる場合に発生し、モデルが1つ以上の冗長な予測変数を生成することを意味します。つまり、モデルが1つ以上の説明変数の係数または影響を正確に計算するのが困難になります。

以下のような表を使用すると、モデルの構築方法を明確にするのに役立ちます：

![data schema](https://facebookexperimental.github.io/Robyn/img/dataSchema.png))

モデルを設計したら、Robynに対しどのような仕様でモデリングを行なうかをコードのいくつかのパラメータで設定する必要があります：

- **係数の符号を制御する**：Robynで係数設定に「default」を設定すると、対応する変数はモデリング結果に応じて正または負の係数を持つことができます。しかし、時には説明変数が目的変数に特定の影響を与えると想定するのが理にかなっています。例えば、競合他社の売上は自社の売上に対してマイナスの影響を与えるべきですし、広告主のメディア活動は売上にプラスの影響を与えるはずです。この場合、パラメータ設定で係数の符号を「positive」または「negative」として直接制御することができます。

- **有料メディア、オーガニック、コンテキスト変数への変数の分類**: Robynでは、入力変数を有料メディア、オーガニック、コンテキストの3つのタイプに分類します。各タイプにどの変数を分類するかについて、以下の一般的な考慮事項を確認してください：

  - **`paid_media_vars`**：マーケティング支出が伴うメディア変数は、このカテゴリに分類されます。キャリーオーバー効果（アドストック）と飽和効果（後述のデータ変換技術を参照）を反映するため、有料メディア変数にはデータ変換技術が適用されます。これらの変数には、メディア露出をよりよく反映するインプレッション、クリック、GRPなどのメトリックを使用することを推奨します。利用可能でない場合、最後の手段として支出を使用することができます。

  - **`organic_vars`**：明確なマーケティング支出が伴わないマーケティング活動は、このカテゴリに含まれます。通常、これにはメールマガジン、プッシュ通知、ソーシャルメディアの投稿などがあります。オーガニック変数は、有料メディア変数と同様のキャリーオーバー（アドストック）と飽和効果が期待されるため、同様の変換技術が適用されます。

  - **`context_vars`**: これには、有料またはオーガニックメディアではないが、目的変数を説明するのに役立つその他の変数が含まれます。最も一般的な例は、競合他社の活動、価格とプロモーション活動、失業率などのマクロ経済要因です。これらの変数には変換技術は適用されず、従属変数に直接影響を与えると期待されます。

  - **`organic_vars`** および **`context_vars`** は、カテゴリカルまたは連続データを受け入れることができますが、**`paid_media_vars`** は連続データのみを受け入れます。オーガニックまたはコンテキスト変数がカテゴリカルである場合は、どの変数がカテゴリカルであるかを **`factor_vars`** パラメータで指定する必要があります。同じ変数に対して、連続データはカテゴリカルデータよりもモデルに多くの情報を提供することができます。たとえば、各プロモーションの割引率（連続データ）を指定する方が、プロモーションの存在を0と1で示すダミー変数を使用するよりも、モデルに正確な情報を提供します。

- **インプレッション対支出**:

  [データ収集](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM/　#data-collection) セクションで触れたように、モデリングにはメディア露出指標（インプレッションやGRPなど）を使用することが推奨されています。非推奨ではありますが、ROI（投資対効果）を計算し、予算配分をシミュレートするためにもメディア支出を収集する必要があります。 **`paid_media_vars`** で支出の代わりに露出変数（インプレッションなど）を使用する場合、Robynは露出と支出の関係を確立するために、露出と支出の間の非線形モデルをMichaelis Menten関数で適合させます（公式Robyn github [ページ](https://github.com/facebookexperimental/Robyn)で「Spend exposure plot」を検索して詳細を確認してください）。最後に露出量を支出額に戻すプロセスについて心配する必要はありません。露出指標を使用することがベストプラクティスですが、一部の状況では支出をモデリング目的で使用する必要があります：

  - メディア露出メトリックが収集可能である場合；
  - 露出量と支出額のデータがモデルに適合しない場合、たとえば、複数のチームがFacebook広告の異なる戦略（入札、目的、オーディエンスなど）を使用している大手広告主の場合、Facebook全体のレベルでのインプレッションと支出のデータが適合しない可能性があります。Robynはインプレッションと支出がうまく適合していない場合に警告メッセージを表示します。このような状況では、まずFacebookを意味のある変数に分割することを検討する必要があります。しかし、より詳細な分割が不可能である場合、またはインプレッションと支出のデータがすべての分割オプションを試しても依然として適合しない場合は、インプレッションの代わりに支出を使用することを検討してください。

- **入力変数の数を最終的に決定する**：Robynのリッジ回帰（後のセクションでカバー）は相互に相関する説明変数を扱い、過剰適合を防ぎます。したがって、アナリストはどの変数を含めるかを選択する際、より柔軟性を持つことができます。一般的には、n * pデータフレーム（n = モデル化される行数、p = 列数）の場合、nはpの約7〜10倍であることを推奨し、10倍を超えないことを推奨します。最適な入力変数の数が不確かな場合、反復的なプロセスの一部として複数の設計を試す価値があります。

<u>データ変換テクニック</u>

MMMの魅力の一部は、アドストック効果と飽和効果といった主要なマーケティング原則に基づいていることで、これらの原則はRobynにも反映されます：

- **アドストック**：マーケティングキャンペーンの残存効果をより良く、より正確に表現するのに非常に役立つ技術です。さらに、この効果はキャンペーン計画に利用することができます。アドストックは広告効果が初回露出後に遅延し、減衰するという理論を反映しています。つまり、広告の効果はすぐには感じられず、意識が高まり、人々が後続の週に行動するまでに時間がかかる場合があり、この認識は時間とともに減少するということです。
- **飽和効果**：飽和効果の理論は、広告露出を増やすごとに得られる効果が増加するが、その割合は減少するというものです。これはMMMとRobynに反映されている主要なマーケティング原則であり、変数変換に反映されています。

これらに関するより技術的な詳細は[ここ](https://facebookexperimental.github.io/Robyn/docs/features#variable-transformations)確認できますが、ハイパーパラメータの調整を行う前にそれぞれの意味を正しく理解することが重要です。不確かな場合は、以下に説明する推奨設定をそのまま使用できます。

<em>アドストック</em>

Robynでは、2種類のアドストックテクニックを選択することができます。各アプローチがモデルの目的とビジネスの目的に合っているか見つけるために、さまざな変換パターンをテストすることを推奨します。

1. **Geometric**：Geometric変換の最大の利点はそのシンプルさです。これは「theta」と呼ばれる1つのパラメータのみを必要とし、直感的に理解しやすいです。たとえば、theta = 0.75のアドストックは、期間1のインプレッションの75%が期間2に持ち越されることを意味します。これにより、技術に明るくないステークホルダーに結果を伝えるのがはるかに簡単になります。さらに、GeometricはWeibullよりも実行が速いです。Weibullは2つのパラメータを最適化する必要があります。

ただし、Geometricはシンプルすぎると考えられることがあり、デジタルメディアの変換には適していないとされています。この[研究](https://github.com/annalectnl/weibull-adstock/blob/master/adstock_weibull_annalect.pdf)で示されています。Geometric変換はthetaが唯一調整可能なパラメータであり、固定された減衰率を反映します。たとえば、1日目のTV支出が100€で、シータ = 0.7の場合、2日目は1日目から70€の効果が持ち越され、3日目は2日目から49€の効果が持ち越されます。一般的なメディアチャンネルのルールは以下です：

    - TVCM = c(0.3, 0.8)
    - 屋外広告（OOH）/チラシ/ラジオ = c(0.1, 0.4)
    - デジタル広告 = c(0, 0.3)

2. **Weibull**：従来のGeometricアドストックは非常に人気がありますが、Ekimetrics & Annalectによって報告された最近の研究では、Weibull生存関数/Weibull分布がFacebookなどの現代的なメディア活動により適していることが示されています。Weibull生存関数/Weibull分布は、分布の形状とスケールの柔軟性を大幅に向上させます。ただし、WeibullはGeometricよりも実行に時間がかかります。これは、2つのパラメータ（shapeとscale）を最適化する必要があるためであり、技術に明るくないステークホルダーに説明するのが難しいことがあります。

Weibull変換のハイパーパラメータを設定する際には、どのタイプのWeibull変換を使用するかによって異なります：
- **Weibull CDF アドストック**：Weibull累積分布関数（CDF）には、shapeとscaleの2つのパラメータがあります。Geometircアドストックが固定の減衰率を想定するのに対し、Weibull CDFアドストックは柔軟な減衰率を提供します。
  - shapeパラメータは減衰曲線の形状を制御します。推奨される範囲はc(0.0001, 2)です。形状が大きいほど、よりS形、小さいほどL形の曲線になります。
  - scaleパラメータは減衰曲線の屈折点を制御します。保守的な範囲としてc(0, 0.1)が推奨です。scaleはアドストックの半減期を大幅に延長する可能性があります。

- **Weibull PDF アドストック**:Weibull確率密度関数（PDF）も、shapeとscaleの2つのパラメータを持ち、Weibull CDFと同様に柔軟な減衰率を提供します。Weibull PDFとCDFの違いは、Weibull PDFが遅延効果を提供する点です。

  shapeパラメータについて:
    - shape > 2の場合、曲線はx = 0の後にピークがあり、x = 0で傾斜がゼロになります。これにより、アドストックの増加と減少が鋭くなります。scaleパラメータはx軸でのピークの相対位置を示します。
    - 1 < shape < 2の場合、曲線はx = 0の後にピークがあり、x = 0で無限大の正の傾きを持ちます。これにより、アドストックの増加と減少が緩やかになります。scaleは上記と同じ効果を持ちます。
    - shape = 1の場合、曲線はx = 0でピークに達し、指数関数的に減少します。scaleは屈折点を制御します。
    - 0 < shape < 1の場合、曲線はx = 0でピークに達し、減衰が増加していきます。scaleは屈折点を制御します。

  形状についてはすべての可能な形が関連していますが、c(0.0001, 10)を形状の範囲として推奨します。強い遅延効果が関心事である場合は、形状に対してc(2.0001, 10)を推奨します。

  スケールについては、c(0, 0.1)の範囲が推奨です。

Weibull PDFの柔軟性の高さと、Nevergradによる探索の自由度のため、モデリングには多くの反復が必要です。

もし上記の説明が複雑すぎる場合は、Robynが提供するアドストックヘルパープロットを参照して、3つのアドストックオプション（Geometric、Weibull CDF、Weibull PDF）がパラメータの変化に応じてデータをどのように変換するかを視覚化することができます。以下に例のチャートを示します：

![ad stock curves](https://facebookexperimental.github.io/Robyn/img/adstock-qs.png))

<em>飽和（サチュレーション）</em>

Robynは各メディアチャンネルの飽和を反映するためにHill関数を使用します。Hill関数はRobynにおいて2つのパラメータを持つ関数で、alphaとgammaのパラメータを持ちます：
- alphaは曲線の形状を指数型からS型に制御します。c(0.5, 3)の範囲が推奨です。alphaが大きいほどS字型になり、alphaが小さいほどC字型になることに注意してください。
- gammaは反応曲線の屈折点を制御します。c(0.3, 1)の範囲が推奨です。gammaが大きいほど、反応曲線の屈折点が遅くなります。

ヘルパープロットで、パラメータが変化するにつれてHill関数がどのように変換されるかを確認することができます。以下にいくつかの例を示します：

![hill curves](https://facebookexperimental.github.io/Robyn/img/hillFunction1.png))

### モデリングのテクニック
パラメータを設定し終えたら、最初のモデルを実行する時です。一度パラメータが設定されると、Robynのモデリングプロセスは自動化され、指定し仕様に従って結果が自動的に生成されます。この部分ではあまり介入が必要ありませんが、何が起こっているのか、どのように結果を解釈するかを理解することが重要です。

<u>リッジ回帰</u>

MMMは回帰モデリングを使用し、目的変数を記述する方程式を導出することを目指します。モデルは各説明変数に係数を割り当てることを目指し、モデル内に統計的に有意な変数のみが残ります。

非常に単純な用語で表現すると、以下のモデルはKPIがすべての要因からどのように影響を受けるかを示します（Robynモデルのより詳細な方程式については[こちら](https://facebookexperimental.github.io/Robyn/docs/features#ridge-regression/)を参照してください）：

\[ KPI_t = \beta_0 + \beta_1x_1 +  \beta_2x_2 + \beta_3x_3 + \beta_4x_4 + \ldots + \beta_nx_n \]

- \( KPI_t \)：モデル化したい時間\( t \)のKPI
- \( \beta_0 \)：ベースライン、つまり他のすべての要因が最小である場合のパフォーマンス
- \( \beta \)：係数、つまり変数\( x \)の変化がKPIに与える影響

過剰適合（オーバーフィット）と多重共線性（マルチコ）は回帰分析で一般的に対処される問題です。モデルを過剰適合させると、予測力が低下します。これは、モデルの柔軟性を奪ってしまうからです。一方、変数が不足していると適合不足（アンダーフィット）に陥り、特定のチャネルの結果が不適切になる可能性があります。多くの回帰子の間で多重共線性を扱い、過剰適合を防ぐために、正則化技術を適用して分散を減少させることでバイアスを導入しています。このアプローチは通常、MMMの予測性能を向上させます。

Robynで使用される最も一般的な正則化はリッジ回帰であり、その数学的背景については[このページ](https://facebookexperimental.github.io/Robyn/docs/features#ridge-regression)で詳しく説明されています。Robynではリッジ回帰が自動的に組み込まれており、設定する必要がある項目はほとんどありません。ただし、さらに設定を行いたい場合は、以下のヒントを参照してください。

**<em>より専門的なヒント：リッジ回帰でペナルティの量を制御する</em>**

*<em>警告：正則化技術に基本的な理解がある方にのみ推奨</em>*

リッジ回帰における正則化技術は、回帰モデルをペナルティで処理することによって達成されます。つまり、リッジ回帰は、目的変数に対する寄与が少ない変数の係数をゼロに近づけます。

ペナルティの量を制御するには、リッジ回帰のλ(ラムダ)パラメータを制御します。ラムダが増加すると、収縮の影響が増大し、分散は減少しますがバイアスは増加します。逆に、ラムダが減少すると、ペナルティの影響が減少し、分散は増加しますがバイアスは減少します。

Robynでは、最小誤差から1標準誤差離れたλ、つまりlambda.1seを使用しています。lambda.1seはλを選択する際の一般的なルールであり、[glmnet](https://glmnet.stanford.edu/articles/glmnet.html)のデフォルト設定です。しかし、時にはこの経験則が意図したとおりに機能しないこともあります。その場合、robyn_run関数のlambda_controlパラメータでlambda.min（ペナルティが少ない）とlambda.1seの間でλを制御することができます。

<u>モデル選択</u>

モデル選択は、Robynのモデリングプロセスにおける核心部分です。手動でMMMを構築することは調整するパラメータが多いため、非常に時間がかかるプロセスであることが多いです。（[フィーチャーエンジニアリング](https://facebookexperimental.github.io/Robyn/docs/analysts-guide-to-MMM/#feature-engineering) セクションの **データ変換技術** パートを参照してください）。異なるハイパーパラメータを調整することには、多くの主観的な決定、モデリング経験、何百回もの反復が含まれ、ゼロからMMMを構築するのに数ヶ月かかる可能性があります。幸いなことに、Robynはモデリングプロセスの大部分を自動化することで、モデルの実行にかかる時間を短縮し、"分析者のバイアス"を減らすことができます。

Robynは、最適な結果を自動的に返すことにより、モデル選択プロセスを半自動化します。これを実現するために、RobynはMetaの進化的最適化プラットフォームである[Nevergrad](https://facebookresearch.github.io/nevergrad/)の多目的最適化機能を利用します。最適なハイパーパラメータを選択する際に、RobynはNevergradに2つの目標を達成するように依頼します：
- **モデルの当てはまり**：モデルの予測誤差（NRMSE、normalized root-mean-square error、正規化平方根平均二乗誤差）を最小限に抑える
- **ビジネスの当てはまり**：分解距離（DECOMP.RSSD、decomposition root-sum-square distance、分解ルート和二乗距離）を最小限に抑える。この距離はチャネルの支出シェアとチャネルから得られる効果のシェア（係数分解シェア）の関係を考慮しています。この距離が遠すぎると、その結果は非現実的になる可能性があります（例：最小の支出を持つメディア活動が最大の効果を得る）。

下のチャートは、Nevergradが「悪いモデル」（予測誤差が大きい/または非現実的なメディア効果）の大部分を排除する方法を詳述しています。チャート上の各ドットは探索されたモデルソリューション（ハイパーパラメータサンプリングの1単位）を表し、左下の角の線はパレートフロント1~3で、すべての反復から得られる最適なモデル結果が含まれています。2つの軸（x軸のNRMSEとy軸のDECOMP.RSSD）は最小化する必要がある2つの目的関数です。反復が進むにつれて、座標の左下隅に向かって収束が進んでいます。これは、Nevergradがモデル結果を最適な方向に向けて最適化を進めているる証拠です。

![pareto_front](https://facebookexperimental.github.io/Robyn/img/pareto_front.png))

モデリングプロセスの最後に、RobynはNRMSEとDECOMP.RSSD関数に基づいて初期の出力として一連のモデルを生成します。ユーザーのビジネス知識と要件を考慮してチャートをレビューした後、ユーザーによって最終モデルを選択する必要があります。出力の解釈方法についての詳細は[ここ](https://facebookexperimental.github.io/Robyn/docs/features#outputs--diagnostics)で見ることができます。

<em>すべてのパレート最適出力の中から最終モデルを選択するためのベストプラクティスは何ですか？</em>

自動的に最適なモデルを選択するのではなく、ユーザーに最終モデルを選択させる理由は2つあります：
- MMMは複雑なプロセスであるため、私たちはいくつかの統計パラメータを使用するだけでは、さまざまなビジネスコンテキストや異なる企業を反映するモデルを正確に選択できないと考えています；
- Robynはオープンソースであり、透明性を重視して設計されています。そのため、Robynをブラックボックスソリューションとしないため、透明性の精神でユーザーが最終決定を下させる仕様となっています

以下は、最終モデルを選択する際の一般的な考慮事項です：

- **リフトテストによる補正（キャリブレーション）**：MMMにリフトテストの結果を統合することは、モデル選択の最良の選択肢と考えられます。このセクションの後半で詳細をカバーします。
- **ビジネスインサイトに関わるパラメータ**：モデルを評価する際、結果がビジネスコンテキストと一致するかどうかを確認するために、複数のビジネスインサイトに関わるパラメータを確認できます。ROI、アドストックおよびレスポンスカーブ、支出と効果のシェアなど、レビューするビジネスパラメータは複数あります。以前のMMM/MTAの結果、業界ベンチマークなど、パフォーマンスに関する強い事前知識がある場合も最終モデルを決定する際の良い参考となる可能性があります。
- **ROASの収束**：下のチャートもモデルを選択するのに役立ちます。これは、時間をかけ反復を行うことで有料メディアのROIまたはROASがどのように進化するかを示しています。一部のチャネルでは、反復が進むことでROASの収ROASの分布にピークが発生しており、特定のチャネルの結果に対するより高い信頼を示しています。

![roasdistributionchart](https://facebookexperimental.github.io/Robyn/img/roasdistributions.png))

- **統計指標**：複数のモデルがビジネスインサイトに関わるパラメータで非常に似た傾向を示している場合、最も統計指標（例えば、最高の調整済みR二乗、最低のNRMSEなど）が良いモデルを単に選択することができます。

<em>より専門的なヒント：Nevergrad最適化のパラメータ設定オプション</em>

- **反復回数**：Robynは多くの反復（例：Geometricアドストックに対して2000反復 x 5試行）を推奨しています。データセットが大きいほど、収束に必要な反復回数が多くなります。ただし、コードの実行方法を素早く確認したい場合は、反復回数を大幅に減らすことで時間を節約できます。しかし、この結果を意思決定に使用することはお勧めしません。
- **パレートフロントラインの数**：もしパレート最適結果のスペクトルを増やしたい場合は、robyn_run関数でパレートフロントラインの数を増やすことができます（デフォルトは3フロントラインです）。

<u>モデルの補正</u>

上述の通り、リフトテストおよび因果関係に基づく結果を考慮することで、MMMを補正することを強く推奨します。例えば、[Meta Conversion Lift](https://www.facebook.com/business/m/one-sheeters/conversion-lift)などの人ベース、または[Meta GeoLift](https://github.com/facebookincubator/GeoLift)などのエリアベースの測定手法は、広告の真の増分効果を把握するために使用できる2つの方法論です。これらの実験の結果を適用することで、モデルの精度が向上する可能性が高いです。

モデル選択のところで述べたように、モデルの補正は、特に媒体の効果や性能に関する強力な予備知識がない場合に、最終モデルを選択する際の信頼性を高めることができます。MMMを恒久的に補正するために、継続的かつ定期的にリフトテストを実施することを推奨します。一般的には、リフトテストの結果を、マーケティングチャネルのMMMアウトプットと比較したいです。概念的には、これはベイズ法のようなもので、リフトテスト結果がメディア変数の係数を補正するための事前分布として使用されます。

以下の図は、1つのMMM候補モデルの補正プロセスを示しています。MetaのNevergrad勾配なし最適化プラットフォームを利用して、正規化平均二乗誤差（NRMSE）およびDecomp.RSSD比率に加え、MAPE(cal,fb)を第三の最適化スコアとして含めることができます。これにより、三つの最適化スコアに基づくパレート最適モデル候補の解の集合が得られます。この補正方法は、リフトテストを行っている他のメディアチャネルにも適用できます。補正されるチャネルが多ければ多いほど、MMMモデルの精度が向上します。

![calibrationchart](https://facebookexperimental.github.io/Robyn/img/calibrationchart.png))

モデルの補正に役立つその他のヒント：
- リフトテスト結果とMMMが測定しているもの（目的変数）と一致していることを確認してください（同じ粒度、同じ測定指標、同じ期間など）。
- リフトテストの信頼性が十分でない場合は、その結果を使用しないでください。
- 現在、Robynはモデルの補正の入力として点推定の結果のみを受け入れます。たとえば、チャネルAに対して$10kの支出がホールドアウトとしてテストされた場合、1) 開始日、2) 終了日、3) 純増効果を指定して、リフトテスト結果を点推定として入力します。Robynが点推定のみを受け入れる理由は、リフトテスト結果が一定期間のみの限定的な影響を考慮しているためです。
- リフトテストの期間を長くすることで、ロングテールのコンバージョンをキャプチャし、バイアスを減らすことができます。長期間のテストは結果にノイズが含まれる可能性がありますが、分散を削減するテクニック（例：Meta Conversion Lift）を使用してこれを最小限に抑えることができます。

<u>モデルのリフレッシュ</u>

初期モデルが構築され選択された後、新しいデータが得られるたびにモデルリフレッシュを継続的にじっすするための、**`robyn_refresh()`** 関数を使用できます。この機能により、MMMを定期的に（例：月次、週次、さらには日次で）継続的なレポートツールとして使用でき、MMMがより実用的なものになります。

例えば、最初のビルドを4週間分の新しいデータで更新する場合：
- **`robyn_refresh()`**は初期ビルドで選択されたモデルを使用する;
- そしてRobynは、新しいビルドのためのハイパーパラメータの下限と上限を設定する。これは初期ビルドの選択されたハイパーパラメータと一致する。これにより、初期ビルドと新規ビルドにまたがるコンテクスト変数とオーガニック変数の効果が安定し、メディア変数の新しい効果シェアが新しい追加期間の支出レベルに向かって調整される；
- これが完了すると、Robynは、レポート目的のための初期構築と新規構築、およびそれらに対応するプロットを含む集計結果を作成する。

例えば、2017-2018年をカバーする初期時期を基にした5つの異なる時期のモデルリフレッシュを作成する例を以下に示します：

![refresh-window](https://facebookexperimental.github.io/Robyn/img/refresh-window.png))

各リフレッシュ期間の結果セットも生成され、そこにはモデル内の各変数のROIや効果が含まれます。ベースライン変数は、すべてのProphet変数（例：トレンド、季節性、平日、祝日）とインターセプトの合計です。このプロットを基に、異なるビジネスレバーからの影響が時間とともにどのように変化するかを把握することができます。チャートはシミュレーションデータに基づくもであり、実際の意味を持ちません：

![ROASrefreshchart](https://facebookexperimental.github.io/Robyn/img/ROASrefreshchart.png))

モデルのリフレッシュを行うことが常に最良のアプローチであるとは限りません。モデルの再構築がより適切なシナリオである場合もあります：
- **新しいデータが多い場合**：初期モデルが100週をカバーしており、80週分の新しいデータをリフレッシュとして追加する必要がある場合、モデルを再構築する方が良いかもしれません。
- **新しい変数を追加する場合**: 新しい変数を追加する必要がある場合は、モデルデザインを変更する必要があるため、モデルを再構築する方が良いでしょう。

### モデルの応用

ジョン・ワナメーカーの 「私が広告に使うお金の半分は無駄になっている」という言葉を聞いたことがあるかもしれません。MMMとRobynの利点のひとつは、すべての広告の効果を測定し、さまざまなマーケティング活動の効果を改善するための実用的な洞察を提供できることです。そのためには、モデルのアウトプットを正しく解釈できなければなりません。以下のアウトプットとチャートはシミュレーションデータに基づくものであり、説明のためのものであることにご注意ください。

<u>マーケティングミックスモデルのアウトプットを解釈する</u>。

実用的な意思決定を可能にするために、Robynは以下のようなアウトプットとチャートを作成します。


<em>モデルの適合度</em>: 正確なモデルとはモデル化されたデータの適合度が提供された実際のデータに対して正確である必要があります。モデル設計のセクションで述べたように、モデルをオーバースペックにすると予測力が低下しますが、十分な変数を持たず、アンダースペックにすると、特定のチャネルの結果が不適切なものになる可能性があります。下のグラフは、モデル化されたデータと実際のデータを比較した、適合度の高いモデルの例です。この例では、赤い線が前週までの売上の実績値で、青い線がモデルから予測された売上を表しています。

モデラーは、高いR二乗値を目指すべきで、一般的な経験則は以下の通りです。

- R2乗 < 0.8 = 理想的でないため、改善を目指す；
- 0.8 ＜ R2乗 ＜ 0.9 ＝ 許容範囲であり、可能なら改善を目指す；
- R2乗 ＞ 0.9 ＝ 理想的


R2乗値が低いモデルは、改善できる可能性が高いです。改善のための一般的な方法は、より包括的な説明変数を利用すること、つまりより大きな有料メディアチャネルを分割すること、または目的変数を説明する可能性のある追加のベースライン（非メディア）変数を含めることが含まれます。

<img alt="modelfitchart" src={https://facebookexperimental.github.io/Robyn/img/modelfitchart.png}/>


<em>目的変数への寄与度</em>：実際のデータとモデル化されたデータを比較できることに加えて、モデルが導き出した各説明変数の目的変数への寄与度を確認することができます。下のチャートは、このモデルに含まれた他のすべての変数と比較した、売上に対するFacebookの貢献の例を示しています。例えば、下のチャートで、Facebookの2.2%は、総売上の2.2%がFacebookによってもたらされていることを意味します。

<img alt="modeldecompchart" src={https://facebookexperimental.github.io/Robyn/img/modeldecompchart.png}/>


<em>支出のシェア vs 効果のシェアとトータルROI</em>：

  Robynのアウトプットの中には、さらに掘り下げて、より価値のあるインサイトを得ることができるものもあります。下のチャートは、いくつかの異なる指標を比較することで、メディア貢献の詳細な影響を示しています：
  - 支出のシェアは、各チャネルの相対的な支出を反映しています；
  - 効果のシェアは、目的変数への寄与度と同じで、各チャネルによってどれだけの売上増がもたらされたかを示しています；
  - ROI（投資対効果）は、各チャネルの効率性を表し、チャネルによってもたらされた売上増を、そのチャネルに費やされた金額で割って算出されます。

これらの指標は通常、期間ごとに他のメディアチャネルと比較されます。意思決定を行う前に、すべての指標を検討することが重要です。1つのデータポイントに基づいて意思決定を行うと、全体像が反映されない可能性があるからです。例えば
  - ROIは高いが、貢献度や支出額が低いチャネルは、リターンが高く、支出額が低く効果が飽和していない可能性が高いため、支出額を増やせる可能性がある；
  - ROIは低いが、貢献度と支出額が高いチャネルは、成績不振のように見えるので、支出を減らすべきかもしれない。重要なチャネルであることも踏まえ、このチャネルを最適化する方法を検討しましょう。


<img alt="budgetallocatorecochart" src={https://facebookexperimental.github.io/Robyn/img/budgetallocatorecochart.png}/>


<em>レスポンスカーブ</em>：飽和曲線（サチュレーションカーブ）と呼ばれることもあるレスポンスカーブは、特定のチャネルの支出が最適なレベルにあるか、あるいは飽和に近づいているかを示し、それゆえ予算再配分の可能性を示唆します。曲線が変曲点に達し、水平/平坦な傾斜になるのが早ければ早いほど、そのチャネルは支出を追加するごとに飽和していきます。各チャネルのレスポンスカーブを並べて比較することで、成果を改善するために、飽和したチャネルから飽和していないチャネルに費用を再配分する機会についての洞察を得ることができます：

<img alt="saturationlineschart" src={https://facebookexperimental.github.io/Robyn/img/saturationlineschart.png}/>


<em>広告の減衰率（アドストック率）</em>：このチャートは、各チャネルの平均的な減衰率を表しています。減衰率が高いほど、特定のチャネルが最初に露出した後の効果が長いことを意味します。

<img alt="adstockinglineschart" src={https://facebookexperimental.github.io/Robyn/img/adstockinglineschart.png}/>



<u>予算配分</u></u></p

MMMからは多くのアウトプットを得られますが、"ビジネス上の意思決定をするために、すべての結果をどのように使えばいいのか？"、"目的変数への貢献度、ROI、レスポンスカーブなどの複数の結果に基づいて、メディア予算をどのように配分すればいいのか？"という疑問が生じることがよくあります。確かに、MMMのアウトプットに基づく最適な予算配分を見つけることは困難です。幸いなことに、Robynは予算配分機能を提供しており、すべてのモデル結果を使用してさまざまな予算配分をシミュレーション・予測し、実行可能な意思決定を可能にします。

このコードはMetaとRobynコミュニティによって徹底的にレビューされていますが、Budget AllocatorとRobynのどの関数を使っても、予測される結果の正確さに関してビジネスの期待に沿うことを保証するものではありません。実装の前に出力を検証することを検討してください。


選択されたすべてのモデル結果に対して、**robyn_allocator()`**関数を適用することで、レスポンスを最大化する最適な予算構成を得ることができます。最適化できるシナリオは2つあります：
- <em>過去の最大成果</em>：過去の支出額が同じであると仮定し、効果（目的変数）を最大化する最適な予算配分をシミュレートします；
- <em>期待された支出に対する最大成果</em>：予算をいくら使うかをあらかじめ定義した上で、効果（目的変数）を最大化する最適な予算配分をシミュレートします。

Robynの予算配分ツールは、非線形飽和関数（Hill）を解析的に解くために、勾配ベースのnloptrライブラリを使用しています。詳細はnloptrライブラリの[vignette](https://cran.r-project.org/web/packages/nloptr/nloptr.pdf)をご覧ください。

予算配分関数を使用すると、3つのチャートが作成されます：
- <em>初期の予算配分 vs 最適化後の予算配分</em>：このグラフは、効果を最大化するために推奨または最適化された予算配分と、オリジナルの予算配分を比較します。最適化された予算配分が当初より大きい場合、そのチャネルの予算を増やすことが推奨されることを意味します。一方、最適化された予算配分が当初より低い場合、そのチャネルの支出を減らすことが推奨されます。
- <em>初期の平均的な効果 vs 最適化後の平均的な効果</em>：上記と同様に、このグラフは初期と最適化後の期待効果を示します。当初の効果と最適化された効果の差は、前の箇条書きで示したように予算を切り替えた場合に予想される売上の変化の合計です。
- <em>チャネル別のレスポンスカーブと平均支出</em>：<u>マーケティングミックスモデルのアウトプットの解釈</u>で説明したように、レスポンスカーブは、チャネルがどの程度飽和しているか、また、オリジナルと最適化された支出に対して、チャネルが曲線上のどの位置にあるかを示します。

<img alt="予算配分チャート" src={https://facebookexperimental.github.io/Robyn/img/optimizer_new.png} /></img />
